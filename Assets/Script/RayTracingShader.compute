#pragma kernel CSMain
//定义一张2D纹理，RW标识可读写
RWTexture2D<float4> Result;
float4x4 _CameraToWorld;
float4x4 _CameraInverseProjection;

Texture2D<float4> _SkyboxTexture;
SamplerState sampler_SkyboxTexture;
static const float PI = 3.14159265f;

float2 _PixelOffset;
//定义光线射线结构体，用原点+方向表示该射线
struct Ray
{
    float3 origin;
    float3 direction;
    float3 energy;
};

//定义球体结构体
struct Sphere
{
    float3 position;
    float radius;
};
//定义缓存，用来接收脚本传入的数据
StructuredBuffer<Sphere> _Spheres;
//创建射线函数
Ray CreateRay(float3 origin, float3 direction)
{
    Ray ray;
    ray.origin = origin;
    ray.direction = direction;
    ray.energy = float3(1.0f, 1.0f, 1.0f);
    return ray;
}
Ray CreateCameraRay(float2 uv)
{
    // 将相机位置(相机空间的[0,0,0])转到世界空间，作为射线原点
    float3 origin = mul(_CameraToWorld, float4(0.0f, 0.0f, 0.0f, 1.0f)).xyz;
    // 将屏幕上的像素从剪裁空间转到相机空间
    float3 direction = mul(_CameraInverseProjection, float4(uv, 0.0f, 1.0f)).xyz;
    // 将前面得到的位置再转到世界空间
    direction = mul(_CameraToWorld, float4(direction, 0.0f)).xyz;
    //单位化并将其作为射线方向
    direction = normalize(direction);
    return CreateRay(origin, direction);
}
//创建光线交点结构体
struct RayHit
{
    float3 position;
    float distance;
    float3 normal;
};
//创建初始交点，用来判断之后交点的有效性
RayHit CreateRayHit()
{
    RayHit hit;
    hit.position = float3(0.0f, 0.0f, 0.0f);
    //初始化其距原点距离为无限远
    hit.distance = 1.#INF;
    hit.normal = float3(0.0f, 0.0f, 0.0f);
    return hit;
}

void IntersectGroundPlane(Ray ray, inout RayHit bestHit)
{
    // 正常判断应为distance = HitPointPos - Ray.Pos，只要distance < bestHit.distance
    //即为有效碰撞。但这里硬编码地面为xz无限延伸y为0的平面，所以只需要判断y方向的距离即可
    float t = -ray.origin.y / ray.direction.y;
    //判断碰撞距离小于上次碰撞距离即为有效碰撞
    if (t > 0 && t < bestHit.distance)
    {
        bestHit.distance = t;
        bestHit.position = ray.origin + t * ray.direction;
        bestHit.normal = float3(0.0f, 1.0f, 0.0f);
    }
}

//球体碰撞检测，用float4(xyz表示位置，w表示半径)来表示一个球
//光线与球体相交检测
void IntersectSphere(Ray ray, inout RayHit bestHit, Sphere sphere)
{
    // Calculate distance along the ray where the sphere is intersected
    //距离
    float3 d = ray.origin - sphere.position;
    //圆心做作垂线交于射线的点到射线原点距离
    float p1 = -dot(ray.direction, d);
    //半径方减去p1平方为射线交点(如果有)到垂线于射线交点的距离平方
    float p2sqr = p1 * p1 - dot(d, d) + sphere.radius * sphere.radius;
    if (p2sqr < 0)
        return;
    float p2 = sqrt(p2sqr);
    float t = p1 - p2 > 0 ? p1 - p2 : p1 + p2;
    if (t > 0 && t < bestHit.distance)
    {
        bestHit.distance = t;
        bestHit.position = ray.origin + t * ray.direction;
        bestHit.normal = normalize(bestHit.position - sphere.position);
    }
}
RayHit Trace(Ray ray)
{
    RayHit bestHit = CreateRayHit();
    //进行光线追踪检测
//IntersectSphere(ray, bestHit, float4(0,2,0,1));
// 追踪所有球体
    uint numSpheres, stride;
    //在定义的缓存中获取资源维度  资源中结构的数量,每个结构元素的跨度(以字节为单位)
    _Spheres.GetDimensions(numSpheres, stride);
    for (uint i = 0; i < numSpheres; i++)
        IntersectSphere(ray, bestHit, _Spheres[i]);
    return bestHit;
}

    float3 Shade(inout Ray ray, RayHit hit) {
        if (hit.distance < 1.#INF) {
            float3 specular = float3(0.6f, 0.6f, 0.6f);
            float3 albedo = float3(0.8f, 0.8f, 0.8f); //高光反射率
            //Reflect the ray and multiply energy with specular reflection;
            ray.origin = hit.position + hit.normal * 0.001f;
            ray.direction = reflect(ray.direction, hit.normal);
            ray.energy *= specular;
            //Return nothing
            //return float3(0.0f, 0.0f, 0.0f);
            // Shadow test ray
            bool shadow = false;
            /*Ray shadowRay = CreateRay(hit.position + hit.normal * 0.001f, -1 * _DirectionalLight.xyz);
            RayHit shadowHit = Trace(shadowRay);
            if (shadowHit.distance != 1.#INF)
            {
                return float3(0.0f, 0.0f, 0.0f);
            }*/
            return float3(0.0f, 0.0f, 0.0f);
            //return saturate(dot(hit.normal, _DirectionalLight.xyz) * -1) * _DirectionalLight.w * albedo;
        }
        else {
            ray.energy = 0.0f;
            //采样天空盒
            float theta = acos(ray.direction.y) / -PI;
            float phi = atan2(ray.direction.x, -ray.direction.z) / -PI * 0.5f;
            return _SkyboxTexture.SampleLevel(sampler_SkyboxTexture, float2(phi, theta), 0).xyz;
        }
    } 




//申请的线程数
[numthreads(8, 8, 1)]
void CSMain(uint3 id : SV_DispatchThreadID)
{
    // 获取传入的RT的宽高尺寸
    uint width, height;
    // 获取资源尺寸
    Result.GetDimensions(width, height);
    // 将RT的像素位置id.xy转为屏幕像素空间的uv [-1~1]，偏移0.5以便将像素中心作位uv起始
    //float2 uv = float2((id.xy + float2(0.5f, 0.5f)) / float2(width, height) * 2.0f - 1.0f);
    float2 uv = float2((id.xy + _PixelOffset) / float2(width, height) * 2.0f - 1.0f);
    // 
    // 在相机上朝屏幕逐像素创建光线
    Ray ray = CreateCameraRay(uv);
    // 计算光线方向转为uv对天空纹理进行采样
    float theta = acos(ray.direction.y) / -PI;
    float phi = atan2(ray.direction.x, -ray.direction.z) / -PI * 0.5f;
    //采样方式和cg的shader不同，使用Texture.SampleLevel进行采样，最后参数为mipmap的level
    //Result[id.xy] = _SkyboxTexture.SampleLevel(sampler_SkyboxTexture, float2(phi, theta), 0);
    
    // 相交检测并着色
    //Trace and shade

    float3 result = float3(0, 0, 0);
    for (int i = 0; i < 8; i++)
    {
        RayHit hit = Trace(ray);
        result += ray.energy * Shade(ray, hit);
        if (!any(ray.energy))
            break;
    } 
    Result[id.xy] = float4(result, 1);
}